{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ResNet.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "jBDw0dWTwrdx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "debug = True\n",
        "\n",
        "# TODO stride=2 is used in the paper but this is causing shape issues right now :(\n",
        "def conv_3x3(in_channels, out_channels, pad=1, stride=1):\n",
        "    return nn.Conv2d(in_channels, out_channels, 3, stride=stride, padding=pad)\n",
        "\n",
        "\n",
        "class ResidualBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        \"\"\"\n",
        "        A ResidualBlock implements the basic residual block discussed in the paper, for the network used on CIFAR 10.\n",
        "        It consists of a pair of 3x3 convolutional layers, all with the same output feature map size (either 32, 16, or 8)\n",
        "        We apply conv-BN-relu for the first layer, then conv-BN, then add the input (residual connection) and do a final RELU.\n",
        "        We zero-pad the input for dimension mismatches, so that no new parameters are introduced in the residual connections.\n",
        "        \"\"\"\n",
        "        self.in_channels, self.out_channels = in_channels, out_channels\n",
        "        super(ResidualBlock, self).__init__()\n",
        "        self.conv1 = conv_3x3(in_channels, in_channels)\n",
        "        self.bn1 = nn.BatchNorm2d(num_features=in_channels)\n",
        "        self.conv2 = conv_3x3(in_channels, out_channels)\n",
        "        self.bn2 = nn.BatchNorm2d(num_features=out_channels)\n",
        "\n",
        "        \n",
        "    def forward(self, x):\n",
        "        identity = x\n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.bn2(x)\n",
        "        # The paper said that identity shortcuts are used in all cases, \n",
        "        # so in cases of shape mismatch I pad to align dimensions, which introduces no new parameters.\n",
        "        if x.shape != identity.shape:\n",
        "            shape_diff = abs((sum(identity.shape) - sum(x.shape)))\n",
        "            identity = F.pad(identity, pad=(0,0,0,0,shape_diff//2,shape_diff//2))\n",
        "        return F.relu(identity + x)\n",
        "\n",
        "    def __repr__(self):\n",
        "        return f'Residual block with in_channels {self.in_channels} and out channels {self.out_channels}'\n",
        "\n",
        "\n",
        "class Resnet(nn.Module):\n",
        "    def __init__(self, n=1, dbg=False):\n",
        "        super(Resnet, self).__init__()\n",
        "        debug = dbg\n",
        "        self.residual_blocks = []\n",
        "        # create number of residual blocks needed\n",
        "        cur_feature_map_size = 16\n",
        "        changed = False\n",
        "        for i in range(3*n):\n",
        "            if i != 0 and i % n == 0:\n",
        "                cur_feature_map_size = cur_feature_map_size*2\n",
        "                changed = True\n",
        "            block = ResidualBlock(cur_feature_map_size if not changed else cur_feature_map_size//2, cur_feature_map_size)\n",
        "            changed = False\n",
        "            self.residual_blocks.append(block)\n",
        "\n",
        "        self.linear = nn.Linear(16384, 10)\n",
        "        self.conv1 = conv_3x3(3, 16)\n",
        "        self.pool = nn.AvgPool2d(2, stride=2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.conv1(x))\n",
        "        for block in self.residual_blocks:\n",
        "            x = block(x)\n",
        "        # x = self.first_block(x)\n",
        "        # flatten the multidimensional input to a single matix for input into the FC layer\n",
        "        x = self.pool(x) # only difference is this pool\n",
        "        x = x.view(x.shape[0], -1)\n",
        "        x = self.linear(x)\n",
        "        return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "S3A8I7K9wrd3",
        "colab_type": "code",
        "outputId": "6d685d53-e64e-4cc2-eab9-0c874419ecc9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 20210
        }
      },
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from sklearn.metrics import accuracy_score\n",
        "import numpy as np\n",
        "\n",
        "def get_dataset():\n",
        "    transform = transforms.Compose([\n",
        "                transforms.ToTensor(),\n",
        "                transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "            ])\n",
        "    trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "    testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
        "    trainloader = torch.utils.data.DataLoader(trainset, batch_size=128, shuffle=True, num_workers=1)\n",
        "    testloader = torch.utils.data.DataLoader(testset, batch_size=1000, shuffle=False, num_workers=1)\n",
        "    return trainloader, testloader \n",
        "\n",
        "def get_test_accuracy(net, testloader):\n",
        "  accs = []\n",
        "  net.eval()\n",
        "  with torch.no_grad():\n",
        "    for i, data in enumerate(testloader, 0):\n",
        "      x, y = data\n",
        "      x, y = x.cuda(), y.cuda()\n",
        "      preds = resnet(x)\n",
        "      _, predicted = torch.max(preds, 1)\n",
        "      accuracy = accuracy_score(predicted.cpu(), y.cpu())\n",
        "      accs.append(accuracy)\n",
        "      break\n",
        "  net.train()\n",
        "  return np.mean(accs)\n",
        "\n",
        "def update_learning_rate(current_lr, optim):\n",
        "  new_lr = current_lr/10\n",
        "  for g in optim.param_groups:\n",
        "    g['lr'] = new_lr\n",
        "  return new_lr\n",
        "\n",
        "    \n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    num_epochs = 25\n",
        "    # get cifar 10 data\n",
        "    trainloader, testloader = get_dataset()\n",
        "    benchmark, debug = False, True\n",
        "    resnet = Resnet(dbg=debug)\n",
        "    resnet.train()\n",
        "    resnet = resnet.cuda()\n",
        "    for block in resnet.residual_blocks:\n",
        "      block.cuda()\n",
        "    current_lr = 0.1e-4\n",
        "#     optimizer = optim.Adam(resnet.parameters(), lr=1e-4, weight_decay=0.0001)\n",
        "    optimizer = optim.SGD(resnet.parameters(), lr=current_lr, weight_decay=0.0001, momentum=0.9)\n",
        "    train_accs, test_accs = [], []\n",
        "    def train_model():\n",
        "      stopping_threshold, current_count = 3, 0\n",
        "      n_iters = 0\n",
        "      for e in range(num_epochs):\n",
        "        # modify learning rate at \n",
        "          for i, data in enumerate(trainloader, 0):\n",
        "              x, y = data\n",
        "              x, y = x.cuda(), y.cuda()\n",
        "              # zero the grad\n",
        "              optimizer.zero_grad()\n",
        "              preds = resnet(x)\n",
        "              loss = F.cross_entropy(preds, y)\n",
        "              loss.backward()\n",
        "              optimizer.step()\n",
        "              if i % 10 == 0:\n",
        "                  _, predicted = torch.max(preds, 1)\n",
        "                  accuracy = accuracy_score(predicted.cpu(), y.cpu())\n",
        "                  train_accs.append(accuracy)\n",
        "                  print('loss: {}, accuracy: {}'.format(loss, accuracy))\n",
        "              if i % 50 == 0:\n",
        "                # get test accuracy\n",
        "                test_acc = get_test_accuracy(resnet, testloader)\n",
        "                print('test accuracy: {}'.format(test_acc))\n",
        "                test_accs.append(test_acc)\n",
        "              n_iters+=1\n",
        "              if n_iters == 32000 or n_iters == 48000:\n",
        "                current_lr = update_learning_rate(current_lr, optim)\n",
        "      print('iterated {} times'.format(n_iters))\n",
        "      return resnet\n",
        "    \n",
        "    trained_resnet_model = train_model()\n",
        "    \n",
        "                \n",
        "\n"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "loss: 2.367396831512451, accuracy: 0.0859375\n",
            "test accuracy: 0.091\n",
            "loss: 2.3379154205322266, accuracy: 0.1171875\n",
            "loss: 2.319140911102295, accuracy: 0.09375\n",
            "loss: 2.3387510776519775, accuracy: 0.09375\n",
            "loss: 2.321025848388672, accuracy: 0.1015625\n",
            "loss: 2.2964954376220703, accuracy: 0.1015625\n",
            "test accuracy: 0.1\n",
            "loss: 2.332428455352783, accuracy: 0.109375\n",
            "loss: 2.252169370651245, accuracy: 0.125\n",
            "loss: 2.3197128772735596, accuracy: 0.109375\n",
            "loss: 2.2791786193847656, accuracy: 0.09375\n",
            "loss: 2.28896164894104, accuracy: 0.09375\n",
            "test accuracy: 0.118\n",
            "loss: 2.285951614379883, accuracy: 0.1328125\n",
            "loss: 2.2776944637298584, accuracy: 0.15625\n",
            "loss: 2.2602126598358154, accuracy: 0.171875\n",
            "loss: 2.282613754272461, accuracy: 0.109375\n",
            "loss: 2.246964693069458, accuracy: 0.203125\n",
            "test accuracy: 0.133\n",
            "loss: 2.2511887550354004, accuracy: 0.15625\n",
            "loss: 2.2664756774902344, accuracy: 0.125\n",
            "loss: 2.2104454040527344, accuracy: 0.2265625\n",
            "loss: 2.2346014976501465, accuracy: 0.1796875\n",
            "loss: 2.2215771675109863, accuracy: 0.203125\n",
            "test accuracy: 0.159\n",
            "loss: 2.219604730606079, accuracy: 0.1640625\n",
            "loss: 2.236661434173584, accuracy: 0.1796875\n",
            "loss: 2.2567145824432373, accuracy: 0.1953125\n",
            "loss: 2.2407476902008057, accuracy: 0.1875\n",
            "loss: 2.206371307373047, accuracy: 0.21875\n",
            "test accuracy: 0.172\n",
            "loss: 2.18385648727417, accuracy: 0.21875\n",
            "loss: 2.2241547107696533, accuracy: 0.2109375\n",
            "loss: 2.211542844772339, accuracy: 0.234375\n",
            "loss: 2.2359960079193115, accuracy: 0.2265625\n",
            "loss: 2.225027322769165, accuracy: 0.2421875\n",
            "test accuracy: 0.183\n",
            "loss: 2.2241053581237793, accuracy: 0.1171875\n",
            "loss: 2.227250814437866, accuracy: 0.1484375\n",
            "loss: 2.2139878273010254, accuracy: 0.1875\n",
            "loss: 2.2052412033081055, accuracy: 0.1953125\n",
            "loss: 2.2067511081695557, accuracy: 0.2109375\n",
            "test accuracy: 0.205\n",
            "loss: 2.188924551010132, accuracy: 0.234375\n",
            "loss: 2.2001729011535645, accuracy: 0.21875\n",
            "loss: 2.1989762783050537, accuracy: 0.1640625\n",
            "loss: 2.163248062133789, accuracy: 0.2375\n",
            "loss: 2.1643497943878174, accuracy: 0.265625\n",
            "test accuracy: 0.214\n",
            "loss: 2.136976718902588, accuracy: 0.2421875\n",
            "loss: 2.1667110919952393, accuracy: 0.2109375\n",
            "loss: 2.1749939918518066, accuracy: 0.1796875\n",
            "loss: 2.1659133434295654, accuracy: 0.2109375\n",
            "loss: 2.1846468448638916, accuracy: 0.2890625\n",
            "test accuracy: 0.227\n",
            "loss: 2.1495602130889893, accuracy: 0.296875\n",
            "loss: 2.1691739559173584, accuracy: 0.171875\n",
            "loss: 2.1613876819610596, accuracy: 0.265625\n",
            "loss: 2.1219520568847656, accuracy: 0.296875\n",
            "loss: 2.2106168270111084, accuracy: 0.109375\n",
            "test accuracy: 0.238\n",
            "loss: 2.17301869392395, accuracy: 0.21875\n",
            "loss: 2.1145427227020264, accuracy: 0.328125\n",
            "loss: 2.1866047382354736, accuracy: 0.21875\n",
            "loss: 2.1486120223999023, accuracy: 0.25\n",
            "loss: 2.1296699047088623, accuracy: 0.2265625\n",
            "test accuracy: 0.249\n",
            "loss: 2.0975306034088135, accuracy: 0.3515625\n",
            "loss: 2.1664586067199707, accuracy: 0.2890625\n",
            "loss: 2.1324572563171387, accuracy: 0.265625\n",
            "loss: 2.100545644760132, accuracy: 0.3203125\n",
            "loss: 2.10878849029541, accuracy: 0.2421875\n",
            "test accuracy: 0.257\n",
            "loss: 2.1535651683807373, accuracy: 0.203125\n",
            "loss: 2.076357841491699, accuracy: 0.2890625\n",
            "loss: 2.1266417503356934, accuracy: 0.3203125\n",
            "loss: 2.152735471725464, accuracy: 0.2578125\n",
            "loss: 2.141832113265991, accuracy: 0.234375\n",
            "test accuracy: 0.265\n",
            "loss: 2.1763052940368652, accuracy: 0.2421875\n",
            "loss: 2.165052890777588, accuracy: 0.2890625\n",
            "loss: 2.0839240550994873, accuracy: 0.328125\n",
            "loss: 2.0981640815734863, accuracy: 0.2890625\n",
            "loss: 2.1602766513824463, accuracy: 0.234375\n",
            "test accuracy: 0.273\n",
            "loss: 2.111715316772461, accuracy: 0.2421875\n",
            "loss: 2.1104543209075928, accuracy: 0.2734375\n",
            "loss: 2.0707812309265137, accuracy: 0.3203125\n",
            "loss: 2.1249332427978516, accuracy: 0.265625\n",
            "loss: 2.087441921234131, accuracy: 0.2734375\n",
            "test accuracy: 0.277\n",
            "loss: 2.1557106971740723, accuracy: 0.2265625\n",
            "loss: 2.0625240802764893, accuracy: 0.328125\n",
            "loss: 2.1032323837280273, accuracy: 0.3046875\n",
            "loss: 2.0794403553009033, accuracy: 0.275\n",
            "loss: 2.0918195247650146, accuracy: 0.28125\n",
            "test accuracy: 0.28\n",
            "loss: 2.091416120529175, accuracy: 0.2578125\n",
            "loss: 2.1054084300994873, accuracy: 0.265625\n",
            "loss: 2.1192409992218018, accuracy: 0.265625\n",
            "loss: 2.1285793781280518, accuracy: 0.21875\n",
            "loss: 2.1075527667999268, accuracy: 0.3359375\n",
            "test accuracy: 0.293\n",
            "loss: 2.072476387023926, accuracy: 0.21875\n",
            "loss: 2.1400671005249023, accuracy: 0.234375\n",
            "loss: 2.1367063522338867, accuracy: 0.2109375\n",
            "loss: 2.1288235187530518, accuracy: 0.21875\n",
            "loss: 2.063333749771118, accuracy: 0.3359375\n",
            "test accuracy: 0.286\n",
            "loss: 2.1101672649383545, accuracy: 0.265625\n",
            "loss: 2.042839527130127, accuracy: 0.296875\n",
            "loss: 2.0763659477233887, accuracy: 0.28125\n",
            "loss: 2.0513265132904053, accuracy: 0.3125\n",
            "loss: 2.111530303955078, accuracy: 0.2265625\n",
            "test accuracy: 0.294\n",
            "loss: 2.01873779296875, accuracy: 0.3046875\n",
            "loss: 2.095036745071411, accuracy: 0.28125\n",
            "loss: 2.096945285797119, accuracy: 0.2421875\n",
            "loss: 2.0441036224365234, accuracy: 0.265625\n",
            "loss: 2.0523715019226074, accuracy: 0.375\n",
            "test accuracy: 0.303\n",
            "loss: 2.0638179779052734, accuracy: 0.328125\n",
            "loss: 2.10980224609375, accuracy: 0.3125\n",
            "loss: 2.096261978149414, accuracy: 0.28125\n",
            "loss: 2.1020100116729736, accuracy: 0.28125\n",
            "loss: 2.101578950881958, accuracy: 0.25\n",
            "test accuracy: 0.3\n",
            "loss: 2.067350149154663, accuracy: 0.296875\n",
            "loss: 2.024580240249634, accuracy: 0.328125\n",
            "loss: 2.1403074264526367, accuracy: 0.2421875\n",
            "loss: 2.0750060081481934, accuracy: 0.2890625\n",
            "loss: 2.042163133621216, accuracy: 0.4140625\n",
            "test accuracy: 0.298\n",
            "loss: 2.1145975589752197, accuracy: 0.28125\n",
            "loss: 2.0794677734375, accuracy: 0.3359375\n",
            "loss: 2.0343081951141357, accuracy: 0.3125\n",
            "loss: 2.077805519104004, accuracy: 0.265625\n",
            "loss: 2.073432445526123, accuracy: 0.3203125\n",
            "test accuracy: 0.307\n",
            "loss: 2.0860886573791504, accuracy: 0.2734375\n",
            "loss: 2.143510580062866, accuracy: 0.2421875\n",
            "loss: 2.061922550201416, accuracy: 0.265625\n",
            "loss: 2.0902843475341797, accuracy: 0.25\n",
            "loss: 2.0716969966888428, accuracy: 0.2578125\n",
            "test accuracy: 0.311\n",
            "loss: 2.1305291652679443, accuracy: 0.234375\n",
            "loss: 2.066525936126709, accuracy: 0.2578125\n",
            "loss: 2.0757882595062256, accuracy: 0.3203125\n",
            "loss: 2.0565366744995117, accuracy: 0.2578125\n",
            "loss: 2.033430337905884, accuracy: 0.3203125\n",
            "test accuracy: 0.317\n",
            "loss: 2.0820841789245605, accuracy: 0.2421875\n",
            "loss: 2.030003070831299, accuracy: 0.28125\n",
            "loss: 2.0746636390686035, accuracy: 0.2421875\n",
            "loss: 2.050746202468872, accuracy: 0.2734375\n",
            "loss: 2.0660271644592285, accuracy: 0.3203125\n",
            "test accuracy: 0.319\n",
            "loss: 2.0509729385375977, accuracy: 0.2734375\n",
            "loss: 2.0235719680786133, accuracy: 0.2734375\n",
            "loss: 2.0221409797668457, accuracy: 0.3125\n",
            "loss: 2.110459327697754, accuracy: 0.2578125\n",
            "loss: 1.967084288597107, accuracy: 0.328125\n",
            "test accuracy: 0.324\n",
            "loss: 1.9761295318603516, accuracy: 0.3125\n",
            "loss: 2.05465030670166, accuracy: 0.296875\n",
            "loss: 2.0354490280151367, accuracy: 0.2734375\n",
            "loss: 1.9978119134902954, accuracy: 0.2734375\n",
            "loss: 2.0398097038269043, accuracy: 0.2421875\n",
            "test accuracy: 0.318\n",
            "loss: 2.090989828109741, accuracy: 0.203125\n",
            "loss: 2.021087408065796, accuracy: 0.28125\n",
            "loss: 2.040760040283203, accuracy: 0.2578125\n",
            "loss: 2.043426990509033, accuracy: 0.3359375\n",
            "loss: 2.0099658966064453, accuracy: 0.3125\n",
            "test accuracy: 0.323\n",
            "loss: 2.005248785018921, accuracy: 0.28125\n",
            "loss: 1.9468833208084106, accuracy: 0.375\n",
            "loss: 1.9401322603225708, accuracy: 0.3671875\n",
            "loss: 1.9609544277191162, accuracy: 0.359375\n",
            "loss: 2.035762071609497, accuracy: 0.4140625\n",
            "test accuracy: 0.33\n",
            "loss: 2.0396716594696045, accuracy: 0.3515625\n",
            "loss: 2.055886745452881, accuracy: 0.28125\n",
            "loss: 2.0416436195373535, accuracy: 0.265625\n",
            "loss: 2.0742573738098145, accuracy: 0.2890625\n",
            "loss: 1.996392846107483, accuracy: 0.3046875\n",
            "test accuracy: 0.337\n",
            "loss: 2.024484157562256, accuracy: 0.34375\n",
            "loss: 1.9999313354492188, accuracy: 0.328125\n",
            "loss: 1.9721733331680298, accuracy: 0.3515625\n",
            "loss: 1.9861373901367188, accuracy: 0.2875\n",
            "loss: 2.022841453552246, accuracy: 0.2890625\n",
            "test accuracy: 0.335\n",
            "loss: 2.0486552715301514, accuracy: 0.265625\n",
            "loss: 1.999479055404663, accuracy: 0.34375\n",
            "loss: 1.9751513004302979, accuracy: 0.359375\n",
            "loss: 2.0819523334503174, accuracy: 0.2578125\n",
            "loss: 2.064133644104004, accuracy: 0.2578125\n",
            "test accuracy: 0.329\n",
            "loss: 1.948812484741211, accuracy: 0.3359375\n",
            "loss: 2.024564266204834, accuracy: 0.3046875\n",
            "loss: 1.9914718866348267, accuracy: 0.2734375\n",
            "loss: 2.1192469596862793, accuracy: 0.2109375\n",
            "loss: 1.9707916975021362, accuracy: 0.359375\n",
            "test accuracy: 0.334\n",
            "loss: 1.9624215364456177, accuracy: 0.3046875\n",
            "loss: 2.0140323638916016, accuracy: 0.34375\n",
            "loss: 2.049437999725342, accuracy: 0.2421875\n",
            "loss: 2.0477426052093506, accuracy: 0.2890625\n",
            "loss: 1.9958409070968628, accuracy: 0.3203125\n",
            "test accuracy: 0.334\n",
            "loss: 2.0019423961639404, accuracy: 0.3359375\n",
            "loss: 1.9945238828659058, accuracy: 0.2421875\n",
            "loss: 1.9819660186767578, accuracy: 0.3515625\n",
            "loss: 1.9578006267547607, accuracy: 0.375\n",
            "loss: 2.0564613342285156, accuracy: 0.2578125\n",
            "test accuracy: 0.335\n",
            "loss: 1.9476063251495361, accuracy: 0.34375\n",
            "loss: 2.035383939743042, accuracy: 0.265625\n",
            "loss: 1.9938950538635254, accuracy: 0.3203125\n",
            "loss: 2.062934398651123, accuracy: 0.296875\n",
            "loss: 2.021115303039551, accuracy: 0.3515625\n",
            "test accuracy: 0.345\n",
            "loss: 2.103541135787964, accuracy: 0.234375\n",
            "loss: 2.082537889480591, accuracy: 0.28125\n",
            "loss: 2.0180814266204834, accuracy: 0.34375\n",
            "loss: 1.9235388040542603, accuracy: 0.3515625\n",
            "loss: 1.9943902492523193, accuracy: 0.296875\n",
            "test accuracy: 0.34\n",
            "loss: 1.976486325263977, accuracy: 0.3203125\n",
            "loss: 1.9586155414581299, accuracy: 0.390625\n",
            "loss: 1.9784833192825317, accuracy: 0.3515625\n",
            "loss: 1.9274660348892212, accuracy: 0.375\n",
            "loss: 1.980268955230713, accuracy: 0.3515625\n",
            "test accuracy: 0.346\n",
            "loss: 1.8908793926239014, accuracy: 0.34375\n",
            "loss: 1.9610515832901, accuracy: 0.328125\n",
            "loss: 1.9410285949707031, accuracy: 0.34375\n",
            "loss: 1.9769176244735718, accuracy: 0.325\n",
            "loss: 1.99834406375885, accuracy: 0.3203125\n",
            "test accuracy: 0.342\n",
            "loss: 1.9620250463485718, accuracy: 0.3203125\n",
            "loss: 2.009354591369629, accuracy: 0.328125\n",
            "loss: 1.971348524093628, accuracy: 0.328125\n",
            "loss: 1.9148164987564087, accuracy: 0.34375\n",
            "loss: 1.9195127487182617, accuracy: 0.3828125\n",
            "test accuracy: 0.342\n",
            "loss: 1.9426051378250122, accuracy: 0.359375\n",
            "loss: 1.9214138984680176, accuracy: 0.359375\n",
            "loss: 2.0079352855682373, accuracy: 0.3359375\n",
            "loss: 1.9150068759918213, accuracy: 0.390625\n",
            "loss: 2.008347988128662, accuracy: 0.2890625\n",
            "test accuracy: 0.336\n",
            "loss: 1.933361530303955, accuracy: 0.328125\n",
            "loss: 1.8792628049850464, accuracy: 0.390625\n",
            "loss: 1.930833339691162, accuracy: 0.3359375\n",
            "loss: 1.957900881767273, accuracy: 0.328125\n",
            "loss: 1.9569237232208252, accuracy: 0.3203125\n",
            "test accuracy: 0.347\n",
            "loss: 1.9694924354553223, accuracy: 0.3203125\n",
            "loss: 1.8909703493118286, accuracy: 0.4140625\n",
            "loss: 1.9625581502914429, accuracy: 0.3203125\n",
            "loss: 1.8521628379821777, accuracy: 0.421875\n",
            "loss: 1.876543641090393, accuracy: 0.4453125\n",
            "test accuracy: 0.347\n",
            "loss: 1.9607610702514648, accuracy: 0.28125\n",
            "loss: 1.8203238248825073, accuracy: 0.46875\n",
            "loss: 2.0270497798919678, accuracy: 0.34375\n",
            "loss: 2.014796018600464, accuracy: 0.2421875\n",
            "loss: 2.0001959800720215, accuracy: 0.328125\n",
            "test accuracy: 0.355\n",
            "loss: 1.9876437187194824, accuracy: 0.3359375\n",
            "loss: 2.003241539001465, accuracy: 0.34375\n",
            "loss: 1.9545433521270752, accuracy: 0.3671875\n",
            "loss: 2.0183937549591064, accuracy: 0.3203125\n",
            "loss: 1.9603937864303589, accuracy: 0.3046875\n",
            "test accuracy: 0.355\n",
            "loss: 1.892530918121338, accuracy: 0.3671875\n",
            "loss: 1.9385982751846313, accuracy: 0.390625\n",
            "loss: 2.016862630844116, accuracy: 0.3984375\n",
            "loss: 1.9334020614624023, accuracy: 0.359375\n",
            "loss: 1.996866226196289, accuracy: 0.28125\n",
            "test accuracy: 0.35\n",
            "loss: 1.9562336206436157, accuracy: 0.328125\n",
            "loss: 1.9783645868301392, accuracy: 0.3046875\n",
            "loss: 1.9094843864440918, accuracy: 0.3203125\n",
            "loss: 2.0295844078063965, accuracy: 0.275\n",
            "loss: 1.9324842691421509, accuracy: 0.3203125\n",
            "test accuracy: 0.355\n",
            "loss: 1.9404029846191406, accuracy: 0.328125\n",
            "loss: 1.8937004804611206, accuracy: 0.3359375\n",
            "loss: 1.9024778604507446, accuracy: 0.3671875\n",
            "loss: 1.9864870309829712, accuracy: 0.25\n",
            "loss: 1.9121992588043213, accuracy: 0.359375\n",
            "test accuracy: 0.358\n",
            "loss: 1.8929898738861084, accuracy: 0.3046875\n",
            "loss: 1.9379489421844482, accuracy: 0.3359375\n",
            "loss: 1.9406678676605225, accuracy: 0.3203125\n",
            "loss: 1.87747323513031, accuracy: 0.328125\n",
            "loss: 1.8780828714370728, accuracy: 0.390625\n",
            "test accuracy: 0.356\n",
            "loss: 1.9647846221923828, accuracy: 0.3359375\n",
            "loss: 1.9405019283294678, accuracy: 0.390625\n",
            "loss: 1.8876409530639648, accuracy: 0.3515625\n",
            "loss: 1.892080545425415, accuracy: 0.3515625\n",
            "loss: 1.8872696161270142, accuracy: 0.3515625\n",
            "test accuracy: 0.35\n",
            "loss: 1.916562795639038, accuracy: 0.3046875\n",
            "loss: 1.9182322025299072, accuracy: 0.40625\n",
            "loss: 1.9327366352081299, accuracy: 0.2890625\n",
            "loss: 1.9273858070373535, accuracy: 0.4296875\n",
            "loss: 1.9404298067092896, accuracy: 0.34375\n",
            "test accuracy: 0.358\n",
            "loss: 1.8978168964385986, accuracy: 0.3671875\n",
            "loss: 1.8512489795684814, accuracy: 0.4296875\n",
            "loss: 2.010348081588745, accuracy: 0.3046875\n",
            "loss: 1.8207067251205444, accuracy: 0.4765625\n",
            "loss: 1.8799337148666382, accuracy: 0.40625\n",
            "test accuracy: 0.371\n",
            "loss: 1.957025408744812, accuracy: 0.328125\n",
            "loss: 1.9094775915145874, accuracy: 0.3671875\n",
            "loss: 1.8349461555480957, accuracy: 0.40625\n",
            "loss: 1.897916316986084, accuracy: 0.3515625\n",
            "loss: 1.9175869226455688, accuracy: 0.296875\n",
            "test accuracy: 0.366\n",
            "loss: 1.9719818830490112, accuracy: 0.3515625\n",
            "loss: 1.9048583507537842, accuracy: 0.359375\n",
            "loss: 1.9170347452163696, accuracy: 0.375\n",
            "loss: 1.7851977348327637, accuracy: 0.4375\n",
            "loss: 1.9207191467285156, accuracy: 0.421875\n",
            "test accuracy: 0.363\n",
            "loss: 1.8717010021209717, accuracy: 0.3828125\n",
            "loss: 1.8915960788726807, accuracy: 0.40625\n",
            "loss: 1.8453917503356934, accuracy: 0.359375\n",
            "loss: 1.9193559885025024, accuracy: 0.3625\n",
            "loss: 1.9360352754592896, accuracy: 0.3203125\n",
            "test accuracy: 0.363\n",
            "loss: 1.9450467824935913, accuracy: 0.328125\n",
            "loss: 1.9162681102752686, accuracy: 0.2734375\n",
            "loss: 1.9683711528778076, accuracy: 0.3125\n",
            "loss: 1.8897228240966797, accuracy: 0.390625\n",
            "loss: 1.8556963205337524, accuracy: 0.359375\n",
            "test accuracy: 0.364\n",
            "loss: 1.8592143058776855, accuracy: 0.3515625\n",
            "loss: 1.9111818075180054, accuracy: 0.3515625\n",
            "loss: 1.8615221977233887, accuracy: 0.40625\n",
            "loss: 1.9873034954071045, accuracy: 0.25\n",
            "loss: 1.877989411354065, accuracy: 0.390625\n",
            "test accuracy: 0.369\n",
            "loss: 1.945831060409546, accuracy: 0.3359375\n",
            "loss: 1.997633934020996, accuracy: 0.328125\n",
            "loss: 1.8810008764266968, accuracy: 0.390625\n",
            "loss: 1.9260131120681763, accuracy: 0.3671875\n",
            "loss: 1.8761286735534668, accuracy: 0.375\n",
            "test accuracy: 0.368\n",
            "loss: 1.9241760969161987, accuracy: 0.296875\n",
            "loss: 1.8757232427597046, accuracy: 0.375\n",
            "loss: 1.989101767539978, accuracy: 0.296875\n",
            "loss: 1.9675801992416382, accuracy: 0.2734375\n",
            "loss: 1.8448463678359985, accuracy: 0.3984375\n",
            "test accuracy: 0.371\n",
            "loss: 1.9007235765457153, accuracy: 0.3515625\n",
            "loss: 1.914038062095642, accuracy: 0.3359375\n",
            "loss: 1.9578174352645874, accuracy: 0.2890625\n",
            "loss: 1.8831449747085571, accuracy: 0.3203125\n",
            "loss: 1.9381331205368042, accuracy: 0.296875\n",
            "test accuracy: 0.374\n",
            "loss: 1.8362486362457275, accuracy: 0.4609375\n",
            "loss: 1.9160865545272827, accuracy: 0.3046875\n",
            "loss: 1.816184401512146, accuracy: 0.40625\n",
            "loss: 1.9624136686325073, accuracy: 0.296875\n",
            "loss: 1.988404631614685, accuracy: 0.3125\n",
            "test accuracy: 0.375\n",
            "loss: 1.939491629600525, accuracy: 0.328125\n",
            "loss: 1.874063491821289, accuracy: 0.34375\n",
            "loss: 1.888453722000122, accuracy: 0.3515625\n",
            "loss: 1.846368432044983, accuracy: 0.390625\n",
            "loss: 1.8710442781448364, accuracy: 0.3359375\n",
            "test accuracy: 0.378\n",
            "loss: 1.9400182962417603, accuracy: 0.34375\n",
            "loss: 1.9319614171981812, accuracy: 0.328125\n",
            "loss: 1.8645985126495361, accuracy: 0.3671875\n",
            "loss: 1.8311229944229126, accuracy: 0.4\n",
            "loss: 1.9756340980529785, accuracy: 0.28125\n",
            "test accuracy: 0.363\n",
            "loss: 1.9523100852966309, accuracy: 0.28125\n",
            "loss: 1.9023823738098145, accuracy: 0.328125\n",
            "loss: 1.9298208951950073, accuracy: 0.34375\n",
            "loss: 1.9037556648254395, accuracy: 0.390625\n",
            "loss: 1.8411980867385864, accuracy: 0.421875\n",
            "test accuracy: 0.373\n",
            "loss: 1.9231384992599487, accuracy: 0.3671875\n",
            "loss: 1.9190257787704468, accuracy: 0.3515625\n",
            "loss: 1.848052740097046, accuracy: 0.3828125\n",
            "loss: 1.8839465379714966, accuracy: 0.375\n",
            "loss: 1.8294060230255127, accuracy: 0.421875\n",
            "test accuracy: 0.373\n",
            "loss: 1.9669359922409058, accuracy: 0.3515625\n",
            "loss: 1.9425849914550781, accuracy: 0.34375\n",
            "loss: 1.9653773307800293, accuracy: 0.2890625\n",
            "loss: 1.7883639335632324, accuracy: 0.390625\n",
            "loss: 1.9785044193267822, accuracy: 0.3515625\n",
            "test accuracy: 0.375\n",
            "loss: 1.9043487310409546, accuracy: 0.3359375\n",
            "loss: 1.8765572309494019, accuracy: 0.4140625\n",
            "loss: 1.8212039470672607, accuracy: 0.390625\n",
            "loss: 1.8898428678512573, accuracy: 0.3671875\n",
            "loss: 1.9556807279586792, accuracy: 0.3203125\n",
            "test accuracy: 0.375\n",
            "loss: 1.8700084686279297, accuracy: 0.3203125\n",
            "loss: 1.837427020072937, accuracy: 0.3203125\n",
            "loss: 1.8382610082626343, accuracy: 0.40625\n",
            "loss: 1.9183200597763062, accuracy: 0.3828125\n",
            "loss: 1.8893955945968628, accuracy: 0.375\n",
            "test accuracy: 0.38\n",
            "loss: 1.9124051332473755, accuracy: 0.2890625\n",
            "loss: 1.872198462486267, accuracy: 0.3984375\n",
            "loss: 1.938747525215149, accuracy: 0.3125\n",
            "loss: 1.9476126432418823, accuracy: 0.359375\n",
            "loss: 1.8959228992462158, accuracy: 0.34375\n",
            "test accuracy: 0.378\n",
            "loss: 1.8255492448806763, accuracy: 0.3359375\n",
            "loss: 1.8683524131774902, accuracy: 0.359375\n",
            "loss: 1.8306505680084229, accuracy: 0.3984375\n",
            "loss: 1.812261939048767, accuracy: 0.3828125\n",
            "loss: 1.9121434688568115, accuracy: 0.3984375\n",
            "test accuracy: 0.378\n",
            "loss: 1.8374207019805908, accuracy: 0.359375\n",
            "loss: 1.9438594579696655, accuracy: 0.3046875\n",
            "loss: 1.9434382915496826, accuracy: 0.328125\n",
            "loss: 1.887685775756836, accuracy: 0.35\n",
            "loss: 1.8356305360794067, accuracy: 0.3671875\n",
            "test accuracy: 0.377\n",
            "loss: 1.76936936378479, accuracy: 0.4453125\n",
            "loss: 1.891983985900879, accuracy: 0.3046875\n",
            "loss: 1.8357481956481934, accuracy: 0.3828125\n",
            "loss: 1.9608887434005737, accuracy: 0.3046875\n",
            "loss: 1.8272228240966797, accuracy: 0.328125\n",
            "test accuracy: 0.381\n",
            "loss: 1.9209266901016235, accuracy: 0.4375\n",
            "loss: 1.9070065021514893, accuracy: 0.3828125\n",
            "loss: 1.8892288208007812, accuracy: 0.34375\n",
            "loss: 1.8135043382644653, accuracy: 0.3984375\n",
            "loss: 1.7711443901062012, accuracy: 0.4375\n",
            "test accuracy: 0.388\n",
            "loss: 1.8008719682693481, accuracy: 0.3828125\n",
            "loss: 1.7414828538894653, accuracy: 0.4296875\n",
            "loss: 1.8356528282165527, accuracy: 0.390625\n",
            "loss: 1.809130311012268, accuracy: 0.4375\n",
            "loss: 1.8376654386520386, accuracy: 0.5078125\n",
            "test accuracy: 0.384\n",
            "loss: 1.8597908020019531, accuracy: 0.3828125\n",
            "loss: 1.9076005220413208, accuracy: 0.3671875\n",
            "loss: 1.8627511262893677, accuracy: 0.3359375\n",
            "loss: 1.755516529083252, accuracy: 0.4453125\n",
            "loss: 1.8167771100997925, accuracy: 0.40625\n",
            "test accuracy: 0.388\n",
            "loss: 1.8717337846755981, accuracy: 0.3515625\n",
            "loss: 1.7816060781478882, accuracy: 0.421875\n",
            "loss: 1.8862695693969727, accuracy: 0.3046875\n",
            "loss: 1.9014928340911865, accuracy: 0.3671875\n",
            "loss: 1.868070363998413, accuracy: 0.3515625\n",
            "test accuracy: 0.386\n",
            "loss: 1.8458290100097656, accuracy: 0.3828125\n",
            "loss: 1.8739432096481323, accuracy: 0.390625\n",
            "loss: 1.805989146232605, accuracy: 0.3515625\n",
            "loss: 1.859979271888733, accuracy: 0.375\n",
            "loss: 1.7827749252319336, accuracy: 0.375\n",
            "test accuracy: 0.386\n",
            "loss: 1.8579399585723877, accuracy: 0.3515625\n",
            "loss: 1.861760139465332, accuracy: 0.3671875\n",
            "loss: 1.848280429840088, accuracy: 0.34375\n",
            "loss: 1.8217726945877075, accuracy: 0.3984375\n",
            "loss: 1.8267147541046143, accuracy: 0.3515625\n",
            "test accuracy: 0.385\n",
            "loss: 1.8753318786621094, accuracy: 0.3125\n",
            "loss: 1.7917126417160034, accuracy: 0.3984375\n",
            "loss: 1.7919893264770508, accuracy: 0.328125\n",
            "loss: 1.9292490482330322, accuracy: 0.325\n",
            "loss: 1.8597662448883057, accuracy: 0.421875\n",
            "test accuracy: 0.387\n",
            "loss: 1.911486029624939, accuracy: 0.359375\n",
            "loss: 1.8695378303527832, accuracy: 0.34375\n",
            "loss: 1.881471037864685, accuracy: 0.34375\n",
            "loss: 1.7950081825256348, accuracy: 0.3828125\n",
            "loss: 1.7876298427581787, accuracy: 0.3984375\n",
            "test accuracy: 0.385\n",
            "loss: 1.8021538257598877, accuracy: 0.4296875\n",
            "loss: 1.9395723342895508, accuracy: 0.3671875\n",
            "loss: 1.767128586769104, accuracy: 0.375\n",
            "loss: 1.8052947521209717, accuracy: 0.359375\n",
            "loss: 1.778202772140503, accuracy: 0.4375\n",
            "test accuracy: 0.395\n",
            "loss: 1.8065884113311768, accuracy: 0.3984375\n",
            "loss: 1.8682271242141724, accuracy: 0.328125\n",
            "loss: 1.8483566045761108, accuracy: 0.359375\n",
            "loss: 1.9932392835617065, accuracy: 0.3125\n",
            "loss: 1.813209891319275, accuracy: 0.3203125\n",
            "test accuracy: 0.394\n",
            "loss: 1.8732858896255493, accuracy: 0.3515625\n",
            "loss: 1.7823442220687866, accuracy: 0.3671875\n",
            "loss: 1.7887758016586304, accuracy: 0.3984375\n",
            "loss: 1.8180656433105469, accuracy: 0.4140625\n",
            "loss: 1.7588891983032227, accuracy: 0.4140625\n",
            "test accuracy: 0.393\n",
            "loss: 1.8678911924362183, accuracy: 0.375\n",
            "loss: 1.8767176866531372, accuracy: 0.3203125\n",
            "loss: 1.7956660985946655, accuracy: 0.4140625\n",
            "loss: 1.8634682893753052, accuracy: 0.4453125\n",
            "loss: 1.8854265213012695, accuracy: 0.3046875\n",
            "test accuracy: 0.392\n",
            "loss: 1.8560248613357544, accuracy: 0.3671875\n",
            "loss: 1.8135448694229126, accuracy: 0.359375\n",
            "loss: 1.7842552661895752, accuracy: 0.4140625\n",
            "loss: 1.8933980464935303, accuracy: 0.3203125\n",
            "loss: 1.8492790460586548, accuracy: 0.390625\n",
            "test accuracy: 0.386\n",
            "loss: 1.8160429000854492, accuracy: 0.4140625\n",
            "loss: 1.854017734527588, accuracy: 0.3828125\n",
            "loss: 1.8286100625991821, accuracy: 0.4453125\n",
            "loss: 1.795880675315857, accuracy: 0.3515625\n",
            "loss: 1.786569356918335, accuracy: 0.359375\n",
            "test accuracy: 0.387\n",
            "loss: 1.794278621673584, accuracy: 0.4453125\n",
            "loss: 1.9297590255737305, accuracy: 0.28125\n",
            "loss: 1.7851179838180542, accuracy: 0.4375\n",
            "loss: 2.0784921646118164, accuracy: 0.2125\n",
            "loss: 1.8970797061920166, accuracy: 0.3515625\n",
            "test accuracy: 0.389\n",
            "loss: 1.8584014177322388, accuracy: 0.3203125\n",
            "loss: 1.8384445905685425, accuracy: 0.3828125\n",
            "loss: 1.8707760572433472, accuracy: 0.375\n",
            "loss: 1.743327260017395, accuracy: 0.40625\n",
            "loss: 1.8514609336853027, accuracy: 0.3671875\n",
            "test accuracy: 0.393\n",
            "loss: 1.823630690574646, accuracy: 0.3984375\n",
            "loss: 1.8623892068862915, accuracy: 0.3984375\n",
            "loss: 1.8371292352676392, accuracy: 0.2890625\n",
            "loss: 1.7946733236312866, accuracy: 0.3203125\n",
            "loss: 1.7713830471038818, accuracy: 0.3984375\n",
            "test accuracy: 0.391\n",
            "loss: 1.7863293886184692, accuracy: 0.375\n",
            "loss: 1.8345811367034912, accuracy: 0.3359375\n",
            "loss: 1.9014800786972046, accuracy: 0.359375\n",
            "loss: 1.8055157661437988, accuracy: 0.375\n",
            "loss: 1.8393114805221558, accuracy: 0.3671875\n",
            "test accuracy: 0.395\n",
            "loss: 1.7699247598648071, accuracy: 0.4296875\n",
            "loss: 1.8547686338424683, accuracy: 0.3671875\n",
            "loss: 1.740614891052246, accuracy: 0.4375\n",
            "loss: 1.7597806453704834, accuracy: 0.421875\n",
            "loss: 1.8013917207717896, accuracy: 0.375\n",
            "test accuracy: 0.398\n",
            "loss: 1.8644518852233887, accuracy: 0.3828125\n",
            "loss: 1.8225157260894775, accuracy: 0.3828125\n",
            "loss: 1.8763558864593506, accuracy: 0.3671875\n",
            "loss: 1.9031634330749512, accuracy: 0.328125\n",
            "loss: 1.917041301727295, accuracy: 0.3359375\n",
            "test accuracy: 0.395\n",
            "loss: 1.8785098791122437, accuracy: 0.3203125\n",
            "loss: 1.770362138748169, accuracy: 0.4375\n",
            "loss: 1.7860753536224365, accuracy: 0.4140625\n",
            "loss: 1.7507092952728271, accuracy: 0.3515625\n",
            "loss: 1.8170782327651978, accuracy: 0.40625\n",
            "test accuracy: 0.395\n",
            "loss: 1.9092421531677246, accuracy: 0.328125\n",
            "loss: 1.8615962266921997, accuracy: 0.375\n",
            "loss: 1.7719907760620117, accuracy: 0.453125\n",
            "loss: 1.890411138534546, accuracy: 0.296875\n",
            "loss: 1.8530769348144531, accuracy: 0.34375\n",
            "test accuracy: 0.404\n",
            "loss: 1.7420010566711426, accuracy: 0.4375\n",
            "loss: 1.8210387229919434, accuracy: 0.390625\n",
            "loss: 1.8363518714904785, accuracy: 0.390625\n",
            "loss: 1.7918773889541626, accuracy: 0.4\n",
            "loss: 1.8503174781799316, accuracy: 0.359375\n",
            "test accuracy: 0.397\n",
            "loss: 1.7007924318313599, accuracy: 0.4921875\n",
            "loss: 1.7929909229278564, accuracy: 0.3515625\n",
            "loss: 1.7796655893325806, accuracy: 0.3984375\n",
            "loss: 1.8176145553588867, accuracy: 0.375\n",
            "loss: 1.8705710172653198, accuracy: 0.3671875\n",
            "test accuracy: 0.397\n",
            "loss: 1.8646416664123535, accuracy: 0.2734375\n",
            "loss: 1.7719147205352783, accuracy: 0.3515625\n",
            "loss: 1.7550075054168701, accuracy: 0.4609375\n",
            "loss: 1.8586229085922241, accuracy: 0.3515625\n",
            "loss: 1.8851813077926636, accuracy: 0.3359375\n",
            "test accuracy: 0.396\n",
            "loss: 1.7743383646011353, accuracy: 0.421875\n",
            "loss: 1.823394775390625, accuracy: 0.3515625\n",
            "loss: 1.817433476448059, accuracy: 0.359375\n",
            "loss: 1.9078857898712158, accuracy: 0.3671875\n",
            "loss: 1.72314453125, accuracy: 0.453125\n",
            "test accuracy: 0.404\n",
            "loss: 1.6646780967712402, accuracy: 0.5234375\n",
            "loss: 1.7908378839492798, accuracy: 0.3828125\n",
            "loss: 1.7582871913909912, accuracy: 0.3984375\n",
            "loss: 1.8986077308654785, accuracy: 0.34375\n",
            "loss: 1.7294775247573853, accuracy: 0.4296875\n",
            "test accuracy: 0.401\n",
            "loss: 1.9261140823364258, accuracy: 0.3984375\n",
            "loss: 1.7768824100494385, accuracy: 0.4140625\n",
            "loss: 1.8389815092086792, accuracy: 0.3515625\n",
            "loss: 1.8030632734298706, accuracy: 0.3515625\n",
            "loss: 1.763474702835083, accuracy: 0.3984375\n",
            "test accuracy: 0.398\n",
            "loss: 1.7887144088745117, accuracy: 0.421875\n",
            "loss: 1.8079434633255005, accuracy: 0.4140625\n",
            "loss: 1.9205496311187744, accuracy: 0.3671875\n",
            "loss: 1.7029576301574707, accuracy: 0.4375\n",
            "loss: 1.7190934419631958, accuracy: 0.4140625\n",
            "test accuracy: 0.402\n",
            "loss: 1.7960044145584106, accuracy: 0.4140625\n",
            "loss: 1.8611044883728027, accuracy: 0.375\n",
            "loss: 1.780522346496582, accuracy: 0.3828125\n",
            "loss: 1.7281451225280762, accuracy: 0.4453125\n",
            "loss: 1.791003942489624, accuracy: 0.34375\n",
            "test accuracy: 0.403\n",
            "loss: 1.7741594314575195, accuracy: 0.3984375\n",
            "loss: 1.8553967475891113, accuracy: 0.3125\n",
            "loss: 1.7119547128677368, accuracy: 0.3828125\n",
            "loss: 1.8747732639312744, accuracy: 0.3375\n",
            "loss: 1.8469427824020386, accuracy: 0.4296875\n",
            "test accuracy: 0.404\n",
            "loss: 1.8099302053451538, accuracy: 0.4375\n",
            "loss: 1.836873173713684, accuracy: 0.34375\n",
            "loss: 1.8465843200683594, accuracy: 0.40625\n",
            "loss: 1.9169514179229736, accuracy: 0.296875\n",
            "loss: 1.8717330694198608, accuracy: 0.359375\n",
            "test accuracy: 0.407\n",
            "loss: 1.8168892860412598, accuracy: 0.390625\n",
            "loss: 1.8178071975708008, accuracy: 0.40625\n",
            "loss: 1.8536781072616577, accuracy: 0.3515625\n",
            "loss: 1.8278515338897705, accuracy: 0.3671875\n",
            "loss: 1.8002500534057617, accuracy: 0.3515625\n",
            "test accuracy: 0.409\n",
            "loss: 1.7880688905715942, accuracy: 0.3828125\n",
            "loss: 1.7108103036880493, accuracy: 0.421875\n",
            "loss: 1.8169736862182617, accuracy: 0.40625\n",
            "loss: 1.7743159532546997, accuracy: 0.359375\n",
            "loss: 1.8591240644454956, accuracy: 0.40625\n",
            "test accuracy: 0.411\n",
            "loss: 1.7483489513397217, accuracy: 0.4453125\n",
            "loss: 1.8156551122665405, accuracy: 0.3984375\n",
            "loss: 1.9310325384140015, accuracy: 0.359375\n",
            "loss: 1.832841396331787, accuracy: 0.3203125\n",
            "loss: 1.8521567583084106, accuracy: 0.375\n",
            "test accuracy: 0.408\n",
            "loss: 1.7752058506011963, accuracy: 0.3671875\n",
            "loss: 1.733267903327942, accuracy: 0.3671875\n",
            "loss: 1.7042285203933716, accuracy: 0.40625\n",
            "loss: 1.8398847579956055, accuracy: 0.3671875\n",
            "loss: 1.6625181436538696, accuracy: 0.4375\n",
            "test accuracy: 0.406\n",
            "loss: 1.8001182079315186, accuracy: 0.40625\n",
            "loss: 1.833463191986084, accuracy: 0.3828125\n",
            "loss: 1.6746376752853394, accuracy: 0.4765625\n",
            "loss: 1.8448786735534668, accuracy: 0.4296875\n",
            "loss: 1.8192867040634155, accuracy: 0.4296875\n",
            "test accuracy: 0.412\n",
            "loss: 1.7741730213165283, accuracy: 0.3984375\n",
            "loss: 1.889607310295105, accuracy: 0.34375\n",
            "loss: 1.763737440109253, accuracy: 0.4140625\n",
            "loss: 1.8717460632324219, accuracy: 0.34375\n",
            "loss: 1.7902041673660278, accuracy: 0.359375\n",
            "test accuracy: 0.41\n",
            "loss: 1.7900069952011108, accuracy: 0.34375\n",
            "loss: 1.8620672225952148, accuracy: 0.328125\n",
            "loss: 1.7599072456359863, accuracy: 0.3515625\n",
            "loss: 1.7809957265853882, accuracy: 0.425\n",
            "loss: 1.7604047060012817, accuracy: 0.3828125\n",
            "test accuracy: 0.405\n",
            "loss: 1.743730068206787, accuracy: 0.390625\n",
            "loss: 1.810299038887024, accuracy: 0.3359375\n",
            "loss: 1.8274027109146118, accuracy: 0.3046875\n",
            "loss: 1.6868185997009277, accuracy: 0.484375\n",
            "loss: 1.7843849658966064, accuracy: 0.3671875\n",
            "test accuracy: 0.41\n",
            "loss: 1.8000376224517822, accuracy: 0.34375\n",
            "loss: 1.9394439458847046, accuracy: 0.3203125\n",
            "loss: 1.7574602365493774, accuracy: 0.3984375\n",
            "loss: 1.7549668550491333, accuracy: 0.390625\n",
            "loss: 1.6790807247161865, accuracy: 0.4609375\n",
            "test accuracy: 0.412\n",
            "loss: 1.7910144329071045, accuracy: 0.421875\n",
            "loss: 1.7544609308242798, accuracy: 0.4765625\n",
            "loss: 1.7690554857254028, accuracy: 0.3984375\n",
            "loss: 1.6089438199996948, accuracy: 0.515625\n",
            "loss: 1.762181282043457, accuracy: 0.4765625\n",
            "test accuracy: 0.419\n",
            "loss: 1.7907286882400513, accuracy: 0.40625\n",
            "loss: 1.7438486814498901, accuracy: 0.4140625\n",
            "loss: 1.7664685249328613, accuracy: 0.421875\n",
            "loss: 1.6952494382858276, accuracy: 0.375\n",
            "loss: 1.874514102935791, accuracy: 0.3359375\n",
            "test accuracy: 0.411\n",
            "loss: 1.6765234470367432, accuracy: 0.40625\n",
            "loss: 1.8125277757644653, accuracy: 0.421875\n",
            "loss: 1.785951852798462, accuracy: 0.34375\n",
            "loss: 1.8552863597869873, accuracy: 0.3828125\n",
            "loss: 1.7858033180236816, accuracy: 0.3671875\n",
            "test accuracy: 0.414\n",
            "loss: 1.8506829738616943, accuracy: 0.3515625\n",
            "loss: 1.835037112236023, accuracy: 0.3515625\n",
            "loss: 1.7543683052062988, accuracy: 0.40625\n",
            "loss: 1.7371357679367065, accuracy: 0.4375\n",
            "loss: 1.8042010068893433, accuracy: 0.4453125\n",
            "test accuracy: 0.407\n",
            "loss: 1.7567464113235474, accuracy: 0.4140625\n",
            "loss: 1.812862753868103, accuracy: 0.34375\n",
            "loss: 1.6523438692092896, accuracy: 0.4609375\n",
            "loss: 1.759592890739441, accuracy: 0.4296875\n",
            "loss: 1.787877082824707, accuracy: 0.3671875\n",
            "test accuracy: 0.418\n",
            "loss: 1.8523246049880981, accuracy: 0.3671875\n",
            "loss: 1.7570199966430664, accuracy: 0.3671875\n",
            "loss: 1.8382164239883423, accuracy: 0.3203125\n",
            "loss: 1.8035285472869873, accuracy: 0.4125\n",
            "loss: 1.8113404512405396, accuracy: 0.3203125\n",
            "test accuracy: 0.413\n",
            "loss: 1.7964601516723633, accuracy: 0.3359375\n",
            "loss: 1.8429210186004639, accuracy: 0.375\n",
            "loss: 1.8341737985610962, accuracy: 0.34375\n",
            "loss: 1.8200132846832275, accuracy: 0.375\n",
            "loss: 1.6868189573287964, accuracy: 0.4453125\n",
            "test accuracy: 0.412\n",
            "loss: 1.7290695905685425, accuracy: 0.3984375\n",
            "loss: 1.6982917785644531, accuracy: 0.46875\n",
            "loss: 1.8191807270050049, accuracy: 0.3671875\n",
            "loss: 1.771803617477417, accuracy: 0.390625\n",
            "loss: 1.7693902254104614, accuracy: 0.390625\n",
            "test accuracy: 0.427\n",
            "loss: 1.7792328596115112, accuracy: 0.359375\n",
            "loss: 1.7595863342285156, accuracy: 0.421875\n",
            "loss: 1.8166393041610718, accuracy: 0.34375\n",
            "loss: 1.7316678762435913, accuracy: 0.40625\n",
            "loss: 1.7245923280715942, accuracy: 0.453125\n",
            "test accuracy: 0.418\n",
            "loss: 1.7250787019729614, accuracy: 0.4296875\n",
            "loss: 1.6986180543899536, accuracy: 0.375\n",
            "loss: 1.8267412185668945, accuracy: 0.3671875\n",
            "loss: 1.7123241424560547, accuracy: 0.3984375\n",
            "loss: 1.7475882768630981, accuracy: 0.375\n",
            "test accuracy: 0.422\n",
            "loss: 1.8182017803192139, accuracy: 0.3359375\n",
            "loss: 1.7497520446777344, accuracy: 0.3203125\n",
            "loss: 1.7633709907531738, accuracy: 0.3828125\n",
            "loss: 1.6927952766418457, accuracy: 0.4609375\n",
            "loss: 1.697795033454895, accuracy: 0.4296875\n",
            "test accuracy: 0.41\n",
            "loss: 1.6755375862121582, accuracy: 0.3984375\n",
            "loss: 1.7295585870742798, accuracy: 0.4140625\n",
            "loss: 1.7272565364837646, accuracy: 0.359375\n",
            "loss: 1.7902991771697998, accuracy: 0.3828125\n",
            "loss: 1.7281392812728882, accuracy: 0.34375\n",
            "test accuracy: 0.413\n",
            "loss: 1.7470924854278564, accuracy: 0.390625\n",
            "loss: 1.7592129707336426, accuracy: 0.4453125\n",
            "loss: 1.8316010236740112, accuracy: 0.3515625\n",
            "loss: 1.7060811519622803, accuracy: 0.40625\n",
            "loss: 1.6165516376495361, accuracy: 0.5\n",
            "test accuracy: 0.413\n",
            "loss: 1.8381874561309814, accuracy: 0.3125\n",
            "loss: 1.6726394891738892, accuracy: 0.4140625\n",
            "loss: 1.873839020729065, accuracy: 0.3984375\n",
            "loss: 1.7182931900024414, accuracy: 0.45\n",
            "loss: 1.7430917024612427, accuracy: 0.375\n",
            "test accuracy: 0.419\n",
            "loss: 1.7152957916259766, accuracy: 0.4140625\n",
            "loss: 1.7134507894515991, accuracy: 0.4375\n",
            "loss: 1.753425121307373, accuracy: 0.4296875\n",
            "loss: 1.7595757246017456, accuracy: 0.3984375\n",
            "loss: 1.6646050214767456, accuracy: 0.421875\n",
            "test accuracy: 0.415\n",
            "loss: 1.7821917533874512, accuracy: 0.4375\n",
            "loss: 1.771424412727356, accuracy: 0.40625\n",
            "loss: 1.7560770511627197, accuracy: 0.34375\n",
            "loss: 1.7664388418197632, accuracy: 0.46875\n",
            "loss: 1.8029026985168457, accuracy: 0.3671875\n",
            "test accuracy: 0.42\n",
            "loss: 1.6999439001083374, accuracy: 0.3828125\n",
            "loss: 1.8394336700439453, accuracy: 0.4453125\n",
            "loss: 1.6810401678085327, accuracy: 0.4921875\n",
            "loss: 1.6634482145309448, accuracy: 0.421875\n",
            "loss: 1.676335334777832, accuracy: 0.484375\n",
            "test accuracy: 0.417\n",
            "loss: 1.771484375, accuracy: 0.375\n",
            "loss: 1.7839579582214355, accuracy: 0.40625\n",
            "loss: 1.7643638849258423, accuracy: 0.4296875\n",
            "loss: 1.6269614696502686, accuracy: 0.5234375\n",
            "loss: 1.7618077993392944, accuracy: 0.3984375\n",
            "test accuracy: 0.414\n",
            "loss: 1.7599060535430908, accuracy: 0.3984375\n",
            "loss: 1.605847716331482, accuracy: 0.4296875\n",
            "loss: 1.7524807453155518, accuracy: 0.4765625\n",
            "loss: 1.7375065088272095, accuracy: 0.3828125\n",
            "loss: 1.8153022527694702, accuracy: 0.3828125\n",
            "test accuracy: 0.422\n",
            "loss: 1.7897602319717407, accuracy: 0.375\n",
            "loss: 1.739951252937317, accuracy: 0.4609375\n",
            "loss: 1.709573745727539, accuracy: 0.4140625\n",
            "loss: 1.8604620695114136, accuracy: 0.3671875\n",
            "loss: 1.711352825164795, accuracy: 0.3984375\n",
            "test accuracy: 0.421\n",
            "loss: 1.8855617046356201, accuracy: 0.28125\n",
            "loss: 1.8453121185302734, accuracy: 0.3671875\n",
            "loss: 1.6496446132659912, accuracy: 0.515625\n",
            "loss: 1.684921145439148, accuracy: 0.453125\n",
            "loss: 1.6402636766433716, accuracy: 0.484375\n",
            "test accuracy: 0.425\n",
            "loss: 1.735802412033081, accuracy: 0.375\n",
            "loss: 1.7555783987045288, accuracy: 0.4140625\n",
            "loss: 1.8772313594818115, accuracy: 0.3125\n",
            "loss: 1.707996129989624, accuracy: 0.3625\n",
            "loss: 1.7756004333496094, accuracy: 0.4375\n",
            "test accuracy: 0.422\n",
            "loss: 1.661407470703125, accuracy: 0.421875\n",
            "loss: 1.7573096752166748, accuracy: 0.296875\n",
            "loss: 1.707041621208191, accuracy: 0.3828125\n",
            "loss: 1.7497708797454834, accuracy: 0.4375\n",
            "loss: 1.749283790588379, accuracy: 0.3828125\n",
            "test accuracy: 0.42\n",
            "loss: 1.7793455123901367, accuracy: 0.4296875\n",
            "loss: 1.6861804723739624, accuracy: 0.453125\n",
            "loss: 1.7837722301483154, accuracy: 0.4140625\n",
            "loss: 1.7720402479171753, accuracy: 0.3515625\n",
            "loss: 1.7508442401885986, accuracy: 0.390625\n",
            "test accuracy: 0.418\n",
            "loss: 1.66109037399292, accuracy: 0.4140625\n",
            "loss: 1.6918147802352905, accuracy: 0.421875\n",
            "loss: 1.804256558418274, accuracy: 0.390625\n",
            "loss: 1.6930816173553467, accuracy: 0.4765625\n",
            "loss: 1.652641773223877, accuracy: 0.3984375\n",
            "test accuracy: 0.426\n",
            "loss: 1.7154381275177002, accuracy: 0.359375\n",
            "loss: 1.6750478744506836, accuracy: 0.4453125\n",
            "loss: 1.823108196258545, accuracy: 0.34375\n",
            "loss: 1.6776401996612549, accuracy: 0.4375\n",
            "loss: 1.7316654920578003, accuracy: 0.4609375\n",
            "test accuracy: 0.425\n",
            "loss: 1.7227084636688232, accuracy: 0.4453125\n",
            "loss: 1.8118702173233032, accuracy: 0.3828125\n",
            "loss: 1.6717414855957031, accuracy: 0.4609375\n",
            "loss: 1.7522108554840088, accuracy: 0.4375\n",
            "loss: 1.6978472471237183, accuracy: 0.3984375\n",
            "test accuracy: 0.426\n",
            "loss: 1.713057279586792, accuracy: 0.375\n",
            "loss: 1.726818323135376, accuracy: 0.453125\n",
            "loss: 1.7729853391647339, accuracy: 0.3984375\n",
            "loss: 1.7096610069274902, accuracy: 0.4140625\n",
            "loss: 1.7653409242630005, accuracy: 0.4140625\n",
            "test accuracy: 0.421\n",
            "loss: 1.8439180850982666, accuracy: 0.359375\n",
            "loss: 1.6980540752410889, accuracy: 0.375\n",
            "loss: 1.7270410060882568, accuracy: 0.359375\n",
            "loss: 1.776443362236023, accuracy: 0.3671875\n",
            "loss: 1.859163522720337, accuracy: 0.3046875\n",
            "test accuracy: 0.428\n",
            "loss: 1.588045358657837, accuracy: 0.4609375\n",
            "loss: 1.716691017150879, accuracy: 0.4375\n",
            "loss: 1.6593842506408691, accuracy: 0.40625\n",
            "loss: 1.6632379293441772, accuracy: 0.4625\n",
            "loss: 1.7026714086532593, accuracy: 0.4765625\n",
            "test accuracy: 0.423\n",
            "loss: 1.835850715637207, accuracy: 0.2734375\n",
            "loss: 1.7733134031295776, accuracy: 0.3828125\n",
            "loss: 1.7028826475143433, accuracy: 0.3984375\n",
            "loss: 1.8490358591079712, accuracy: 0.375\n",
            "loss: 1.7413296699523926, accuracy: 0.3671875\n",
            "test accuracy: 0.425\n",
            "loss: 1.7375285625457764, accuracy: 0.4140625\n",
            "loss: 1.8143287897109985, accuracy: 0.375\n",
            "loss: 1.8103156089782715, accuracy: 0.3671875\n",
            "loss: 1.732872724533081, accuracy: 0.4375\n",
            "loss: 1.7825101613998413, accuracy: 0.3984375\n",
            "test accuracy: 0.423\n",
            "loss: 1.68084716796875, accuracy: 0.46875\n",
            "loss: 1.765106439590454, accuracy: 0.3828125\n",
            "loss: 1.6550869941711426, accuracy: 0.4765625\n",
            "loss: 1.6972321271896362, accuracy: 0.3671875\n",
            "loss: 1.706721544265747, accuracy: 0.46875\n",
            "test accuracy: 0.431\n",
            "loss: 1.7682840824127197, accuracy: 0.359375\n",
            "loss: 1.8054869174957275, accuracy: 0.359375\n",
            "loss: 1.6495649814605713, accuracy: 0.4296875\n",
            "loss: 1.6254987716674805, accuracy: 0.484375\n",
            "loss: 1.7150804996490479, accuracy: 0.390625\n",
            "test accuracy: 0.435\n",
            "loss: 1.7898657321929932, accuracy: 0.3828125\n",
            "loss: 1.6701740026474, accuracy: 0.3984375\n",
            "loss: 1.6190905570983887, accuracy: 0.46875\n",
            "loss: 1.6886283159255981, accuracy: 0.4296875\n",
            "loss: 1.754331111907959, accuracy: 0.3984375\n",
            "test accuracy: 0.424\n",
            "loss: 1.7232543230056763, accuracy: 0.4609375\n",
            "loss: 1.6534518003463745, accuracy: 0.453125\n",
            "loss: 1.7157862186431885, accuracy: 0.3984375\n",
            "loss: 1.8077727556228638, accuracy: 0.3671875\n",
            "loss: 1.6898231506347656, accuracy: 0.453125\n",
            "test accuracy: 0.423\n",
            "loss: 1.7460931539535522, accuracy: 0.4140625\n",
            "loss: 1.8187062740325928, accuracy: 0.34375\n",
            "loss: 1.8176125288009644, accuracy: 0.3515625\n",
            "loss: 1.7055137157440186, accuracy: 0.375\n",
            "loss: 1.6415702104568481, accuracy: 0.4609375\n",
            "test accuracy: 0.426\n",
            "loss: 1.6333461999893188, accuracy: 0.4296875\n",
            "loss: 1.6760796308517456, accuracy: 0.46875\n",
            "loss: 1.8063838481903076, accuracy: 0.390625\n",
            "loss: 1.762498140335083, accuracy: 0.425\n",
            "loss: 1.7242118120193481, accuracy: 0.375\n",
            "test accuracy: 0.427\n",
            "loss: 1.6763895750045776, accuracy: 0.453125\n",
            "loss: 1.795557975769043, accuracy: 0.375\n",
            "loss: 1.7504748106002808, accuracy: 0.3984375\n",
            "loss: 1.7325809001922607, accuracy: 0.4375\n",
            "loss: 1.675293207168579, accuracy: 0.421875\n",
            "test accuracy: 0.428\n",
            "loss: 1.6633249521255493, accuracy: 0.484375\n",
            "loss: 1.7600458860397339, accuracy: 0.40625\n",
            "loss: 1.7684590816497803, accuracy: 0.359375\n",
            "loss: 1.6253281831741333, accuracy: 0.515625\n",
            "loss: 1.6360957622528076, accuracy: 0.484375\n",
            "test accuracy: 0.426\n",
            "loss: 1.8647764921188354, accuracy: 0.375\n",
            "loss: 1.9193665981292725, accuracy: 0.3359375\n",
            "loss: 1.7112770080566406, accuracy: 0.4609375\n",
            "loss: 1.6754428148269653, accuracy: 0.4296875\n",
            "loss: 1.8118114471435547, accuracy: 0.4375\n",
            "test accuracy: 0.428\n",
            "loss: 1.7518422603607178, accuracy: 0.4609375\n",
            "loss: 1.7268022298812866, accuracy: 0.4296875\n",
            "loss: 1.7367180585861206, accuracy: 0.4375\n",
            "loss: 1.7276091575622559, accuracy: 0.4375\n",
            "loss: 1.6582386493682861, accuracy: 0.515625\n",
            "test accuracy: 0.428\n",
            "loss: 1.7404054403305054, accuracy: 0.3828125\n",
            "loss: 1.7184077501296997, accuracy: 0.40625\n",
            "loss: 1.7405447959899902, accuracy: 0.390625\n",
            "loss: 1.6572613716125488, accuracy: 0.3359375\n",
            "loss: 1.6350314617156982, accuracy: 0.421875\n",
            "test accuracy: 0.428\n",
            "loss: 1.8492034673690796, accuracy: 0.4140625\n",
            "loss: 1.831015706062317, accuracy: 0.375\n",
            "loss: 1.74037766456604, accuracy: 0.359375\n",
            "loss: 1.6680221557617188, accuracy: 0.453125\n",
            "loss: 1.7550737857818604, accuracy: 0.40625\n",
            "test accuracy: 0.437\n",
            "loss: 1.6957858800888062, accuracy: 0.3984375\n",
            "loss: 1.7144042253494263, accuracy: 0.4453125\n",
            "loss: 1.7203410863876343, accuracy: 0.421875\n",
            "loss: 1.6896045207977295, accuracy: 0.4296875\n",
            "loss: 1.650103211402893, accuracy: 0.4296875\n",
            "test accuracy: 0.431\n",
            "loss: 1.7620034217834473, accuracy: 0.34375\n",
            "loss: 1.863648772239685, accuracy: 0.265625\n",
            "loss: 1.7046924829483032, accuracy: 0.3828125\n",
            "loss: 1.7940467596054077, accuracy: 0.4125\n",
            "loss: 1.668358325958252, accuracy: 0.3828125\n",
            "test accuracy: 0.429\n",
            "loss: 1.6975173950195312, accuracy: 0.421875\n",
            "loss: 1.6193550825119019, accuracy: 0.4296875\n",
            "loss: 1.7821522951126099, accuracy: 0.3671875\n",
            "loss: 1.7167084217071533, accuracy: 0.3671875\n",
            "loss: 1.7752553224563599, accuracy: 0.3984375\n",
            "test accuracy: 0.431\n",
            "loss: 1.8154107332229614, accuracy: 0.359375\n",
            "loss: 1.708735466003418, accuracy: 0.4453125\n",
            "loss: 1.7137597799301147, accuracy: 0.40625\n",
            "loss: 1.6273994445800781, accuracy: 0.4296875\n",
            "loss: 1.7355362176895142, accuracy: 0.359375\n",
            "test accuracy: 0.433\n",
            "loss: 1.742936372756958, accuracy: 0.3671875\n",
            "loss: 1.630135416984558, accuracy: 0.4296875\n",
            "loss: 1.6695924997329712, accuracy: 0.3984375\n",
            "loss: 1.8526982069015503, accuracy: 0.375\n",
            "loss: 1.6672896146774292, accuracy: 0.484375\n",
            "test accuracy: 0.44\n",
            "loss: 1.6937921047210693, accuracy: 0.453125\n",
            "loss: 1.6275678873062134, accuracy: 0.4765625\n",
            "loss: 1.645525336265564, accuracy: 0.4375\n",
            "loss: 1.613248348236084, accuracy: 0.4765625\n",
            "loss: 1.7859532833099365, accuracy: 0.3671875\n",
            "test accuracy: 0.432\n",
            "loss: 1.6806954145431519, accuracy: 0.421875\n",
            "loss: 1.5345587730407715, accuracy: 0.5234375\n",
            "loss: 1.7597262859344482, accuracy: 0.40625\n",
            "loss: 1.7399344444274902, accuracy: 0.40625\n",
            "loss: 1.6844900846481323, accuracy: 0.453125\n",
            "test accuracy: 0.437\n",
            "loss: 1.7681165933609009, accuracy: 0.4453125\n",
            "loss: 1.7429370880126953, accuracy: 0.375\n",
            "loss: 1.709124207496643, accuracy: 0.5\n",
            "loss: 1.6029256582260132, accuracy: 0.453125\n",
            "loss: 1.6939923763275146, accuracy: 0.4375\n",
            "test accuracy: 0.433\n",
            "loss: 1.853858232498169, accuracy: 0.375\n",
            "loss: 1.7180856466293335, accuracy: 0.4375\n",
            "loss: 1.7299518585205078, accuracy: 0.375\n",
            "loss: 1.7041831016540527, accuracy: 0.3984375\n",
            "loss: 1.7516652345657349, accuracy: 0.4140625\n",
            "test accuracy: 0.431\n",
            "loss: 1.7307024002075195, accuracy: 0.3828125\n",
            "loss: 1.7377395629882812, accuracy: 0.34375\n",
            "loss: 1.9543392658233643, accuracy: 0.3125\n",
            "loss: 1.7038390636444092, accuracy: 0.425\n",
            "loss: 1.6861004829406738, accuracy: 0.4453125\n",
            "test accuracy: 0.433\n",
            "loss: 1.648537278175354, accuracy: 0.421875\n",
            "loss: 1.655856728553772, accuracy: 0.46875\n",
            "loss: 1.634813904762268, accuracy: 0.5390625\n",
            "loss: 1.7383085489273071, accuracy: 0.3671875\n",
            "loss: 1.6512517929077148, accuracy: 0.4609375\n",
            "test accuracy: 0.437\n",
            "loss: 1.729853868484497, accuracy: 0.421875\n",
            "loss: 1.7058254480361938, accuracy: 0.4375\n",
            "loss: 1.7020870447158813, accuracy: 0.46875\n",
            "loss: 1.6696776151657104, accuracy: 0.515625\n",
            "loss: 1.7793797254562378, accuracy: 0.3984375\n",
            "test accuracy: 0.434\n",
            "loss: 1.7504040002822876, accuracy: 0.390625\n",
            "loss: 1.6613268852233887, accuracy: 0.4609375\n",
            "loss: 1.6337392330169678, accuracy: 0.4375\n",
            "loss: 1.6668514013290405, accuracy: 0.4453125\n",
            "loss: 1.6495695114135742, accuracy: 0.4765625\n",
            "test accuracy: 0.432\n",
            "loss: 1.742272138595581, accuracy: 0.3828125\n",
            "loss: 1.7672103643417358, accuracy: 0.3671875\n",
            "loss: 1.6980029344558716, accuracy: 0.4609375\n",
            "loss: 1.7192208766937256, accuracy: 0.4609375\n",
            "loss: 1.74754798412323, accuracy: 0.375\n",
            "test accuracy: 0.433\n",
            "loss: 1.6914416551589966, accuracy: 0.40625\n",
            "loss: 1.6754379272460938, accuracy: 0.390625\n",
            "loss: 1.6849923133850098, accuracy: 0.4765625\n",
            "loss: 1.6733152866363525, accuracy: 0.421875\n",
            "loss: 1.829723834991455, accuracy: 0.3515625\n",
            "test accuracy: 0.438\n",
            "loss: 1.67965567111969, accuracy: 0.4765625\n",
            "loss: 1.7682923078536987, accuracy: 0.4140625\n",
            "loss: 1.627159595489502, accuracy: 0.390625\n",
            "loss: 1.713212490081787, accuracy: 0.40625\n",
            "loss: 1.7227661609649658, accuracy: 0.4453125\n",
            "test accuracy: 0.436\n",
            "loss: 1.7129905223846436, accuracy: 0.4609375\n",
            "loss: 1.6414973735809326, accuracy: 0.46875\n",
            "loss: 1.7013051509857178, accuracy: 0.40625\n",
            "loss: 1.7013680934906006, accuracy: 0.3671875\n",
            "loss: 1.658305048942566, accuracy: 0.4140625\n",
            "test accuracy: 0.431\n",
            "loss: 1.7968767881393433, accuracy: 0.359375\n",
            "loss: 1.7202458381652832, accuracy: 0.4453125\n",
            "loss: 1.688964605331421, accuracy: 0.46875\n",
            "loss: 1.5623679161071777, accuracy: 0.525\n",
            "loss: 1.7683732509613037, accuracy: 0.375\n",
            "test accuracy: 0.434\n",
            "loss: 1.6918411254882812, accuracy: 0.359375\n",
            "loss: 1.6962076425552368, accuracy: 0.4609375\n",
            "loss: 1.713497519493103, accuracy: 0.4140625\n",
            "loss: 1.6296107769012451, accuracy: 0.4140625\n",
            "loss: 1.7585471868515015, accuracy: 0.3984375\n",
            "test accuracy: 0.432\n",
            "loss: 1.6830719709396362, accuracy: 0.4296875\n",
            "loss: 1.6061311960220337, accuracy: 0.4765625\n",
            "loss: 1.7948039770126343, accuracy: 0.375\n",
            "loss: 1.5535407066345215, accuracy: 0.5\n",
            "loss: 1.6467269659042358, accuracy: 0.421875\n",
            "test accuracy: 0.436\n",
            "loss: 1.5956908464431763, accuracy: 0.5\n",
            "loss: 1.6599677801132202, accuracy: 0.453125\n",
            "loss: 1.6849759817123413, accuracy: 0.4140625\n",
            "loss: 1.7129542827606201, accuracy: 0.4140625\n",
            "loss: 1.6264152526855469, accuracy: 0.4453125\n",
            "test accuracy: 0.437\n",
            "loss: 1.6754305362701416, accuracy: 0.4609375\n",
            "loss: 1.5871132612228394, accuracy: 0.4453125\n",
            "loss: 1.6979939937591553, accuracy: 0.4765625\n",
            "loss: 1.7117773294448853, accuracy: 0.421875\n",
            "loss: 1.6361796855926514, accuracy: 0.421875\n",
            "test accuracy: 0.437\n",
            "loss: 1.6827565431594849, accuracy: 0.40625\n",
            "loss: 1.6288518905639648, accuracy: 0.4375\n",
            "loss: 1.7559844255447388, accuracy: 0.3984375\n",
            "loss: 1.8791905641555786, accuracy: 0.3359375\n",
            "loss: 1.791933298110962, accuracy: 0.3515625\n",
            "test accuracy: 0.438\n",
            "loss: 1.6383825540542603, accuracy: 0.4296875\n",
            "loss: 1.7278512716293335, accuracy: 0.375\n",
            "loss: 1.719246506690979, accuracy: 0.390625\n",
            "loss: 1.7106958627700806, accuracy: 0.453125\n",
            "loss: 1.6912695169448853, accuracy: 0.4375\n",
            "test accuracy: 0.434\n",
            "loss: 1.6616559028625488, accuracy: 0.484375\n",
            "loss: 1.7166566848754883, accuracy: 0.4375\n",
            "loss: 1.6578246355056763, accuracy: 0.453125\n",
            "loss: 1.7937195301055908, accuracy: 0.40625\n",
            "loss: 1.7572202682495117, accuracy: 0.4296875\n",
            "test accuracy: 0.439\n",
            "loss: 1.7107131481170654, accuracy: 0.453125\n",
            "loss: 1.6698144674301147, accuracy: 0.46875\n",
            "loss: 1.62078857421875, accuracy: 0.4921875\n",
            "loss: 1.6826159954071045, accuracy: 0.425\n",
            "loss: 1.7470983266830444, accuracy: 0.453125\n",
            "test accuracy: 0.442\n",
            "loss: 1.7407348155975342, accuracy: 0.40625\n",
            "loss: 1.683519721031189, accuracy: 0.4453125\n",
            "loss: 1.7568755149841309, accuracy: 0.359375\n",
            "loss: 1.6492186784744263, accuracy: 0.4453125\n",
            "loss: 1.7427029609680176, accuracy: 0.4140625\n",
            "test accuracy: 0.45\n",
            "loss: 1.6348235607147217, accuracy: 0.4296875\n",
            "loss: 1.7534435987472534, accuracy: 0.421875\n",
            "loss: 1.6055562496185303, accuracy: 0.46875\n",
            "loss: 1.7167141437530518, accuracy: 0.421875\n",
            "loss: 1.6266758441925049, accuracy: 0.421875\n",
            "test accuracy: 0.438\n",
            "loss: 1.731518030166626, accuracy: 0.40625\n",
            "loss: 1.7336524724960327, accuracy: 0.390625\n",
            "loss: 1.7196623086929321, accuracy: 0.453125\n",
            "loss: 1.7049949169158936, accuracy: 0.4921875\n",
            "loss: 1.6403160095214844, accuracy: 0.4453125\n",
            "test accuracy: 0.44\n",
            "loss: 1.6125574111938477, accuracy: 0.4453125\n",
            "loss: 1.734681248664856, accuracy: 0.375\n",
            "loss: 1.729488492012024, accuracy: 0.3828125\n",
            "loss: 1.715437650680542, accuracy: 0.390625\n",
            "loss: 1.654980182647705, accuracy: 0.40625\n",
            "test accuracy: 0.447\n",
            "loss: 1.6464186906814575, accuracy: 0.40625\n",
            "loss: 1.7226940393447876, accuracy: 0.46875\n",
            "loss: 1.6850123405456543, accuracy: 0.390625\n",
            "loss: 1.7163910865783691, accuracy: 0.3984375\n",
            "loss: 1.6529420614242554, accuracy: 0.46875\n",
            "test accuracy: 0.438\n",
            "loss: 1.6454623937606812, accuracy: 0.4921875\n",
            "loss: 1.7466973066329956, accuracy: 0.3515625\n",
            "loss: 1.5723201036453247, accuracy: 0.5078125\n",
            "loss: 1.5383503437042236, accuracy: 0.5234375\n",
            "loss: 1.7165825366973877, accuracy: 0.3828125\n",
            "test accuracy: 0.442\n",
            "loss: 1.7741409540176392, accuracy: 0.421875\n",
            "loss: 1.63018000125885, accuracy: 0.4609375\n",
            "loss: 1.7399613857269287, accuracy: 0.375\n",
            "loss: 1.5412490367889404, accuracy: 0.5\n",
            "loss: 1.6349210739135742, accuracy: 0.4140625\n",
            "test accuracy: 0.439\n",
            "loss: 1.545685887336731, accuracy: 0.4765625\n",
            "loss: 1.7205520868301392, accuracy: 0.40625\n",
            "loss: 1.6347709894180298, accuracy: 0.46875\n",
            "loss: 1.7557671070098877, accuracy: 0.3875\n",
            "loss: 1.5111323595046997, accuracy: 0.515625\n",
            "test accuracy: 0.441\n",
            "loss: 1.6378992795944214, accuracy: 0.359375\n",
            "loss: 1.660021185874939, accuracy: 0.5\n",
            "loss: 1.6001596450805664, accuracy: 0.4765625\n",
            "loss: 1.7490724325180054, accuracy: 0.4375\n",
            "loss: 1.6958746910095215, accuracy: 0.40625\n",
            "test accuracy: 0.442\n",
            "loss: 1.6682775020599365, accuracy: 0.390625\n",
            "loss: 1.7606122493743896, accuracy: 0.390625\n",
            "loss: 1.7099541425704956, accuracy: 0.4375\n",
            "loss: 1.7072694301605225, accuracy: 0.4453125\n",
            "loss: 1.6216827630996704, accuracy: 0.453125\n",
            "test accuracy: 0.442\n",
            "loss: 1.5728509426116943, accuracy: 0.515625\n",
            "loss: 1.6774832010269165, accuracy: 0.4609375\n",
            "loss: 1.7103315591812134, accuracy: 0.359375\n",
            "loss: 1.6458606719970703, accuracy: 0.4453125\n",
            "loss: 1.581514835357666, accuracy: 0.5\n",
            "test accuracy: 0.451\n",
            "loss: 1.7341203689575195, accuracy: 0.4296875\n",
            "loss: 1.6653177738189697, accuracy: 0.453125\n",
            "loss: 1.5931354761123657, accuracy: 0.4375\n",
            "loss: 1.6203789710998535, accuracy: 0.4609375\n",
            "loss: 1.67496919631958, accuracy: 0.4453125\n",
            "test accuracy: 0.448\n",
            "loss: 1.5908787250518799, accuracy: 0.4453125\n",
            "loss: 1.5479103326797485, accuracy: 0.4921875\n",
            "loss: 1.7163668870925903, accuracy: 0.3515625\n",
            "loss: 1.647460699081421, accuracy: 0.4765625\n",
            "loss: 1.647922396659851, accuracy: 0.40625\n",
            "test accuracy: 0.441\n",
            "loss: 1.7378822565078735, accuracy: 0.4140625\n",
            "loss: 1.592286467552185, accuracy: 0.4609375\n",
            "loss: 1.674075722694397, accuracy: 0.4296875\n",
            "loss: 1.6909791231155396, accuracy: 0.390625\n",
            "loss: 1.6896289587020874, accuracy: 0.421875\n",
            "test accuracy: 0.445\n",
            "loss: 1.5771777629852295, accuracy: 0.4765625\n",
            "loss: 1.7422170639038086, accuracy: 0.3984375\n",
            "loss: 1.6057496070861816, accuracy: 0.46875\n",
            "loss: 1.6490744352340698, accuracy: 0.4453125\n",
            "loss: 1.7418205738067627, accuracy: 0.390625\n",
            "test accuracy: 0.442\n",
            "loss: 1.6834065914154053, accuracy: 0.390625\n",
            "loss: 1.6760051250457764, accuracy: 0.4453125\n",
            "loss: 1.6744369268417358, accuracy: 0.453125\n",
            "loss: 1.581722617149353, accuracy: 0.45\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "MQizB6IiwreG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 162
        },
        "outputId": "047f7c70-0b3c-4f07-acc2-1e09dc686f57"
      },
      "cell_type": "code",
      "source": [
        "n_iters"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-27-465c05ed699f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mn_iters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'n_iters' is not defined"
          ]
        }
      ]
    }
  ]
}